---
title: "R Notebook"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, collapse = TRUE)
```

Exponential forecasting is another smoothing method and has been around since the 1950s.  Where [niave forecasting](ts_benchmarking#naive) places 100% weight on the most recent observation and [moving averages](ts_moving_averages) place equal weight on *k* values, exponential smoothing allows for weighted averages where greater weight can be placed on recent observations and lesser weight on older observations. Exponential smoothing methods are intuitive, computationally efficient, and generally applicable to a wide range of time series. Consequently, exponentially smoothing is a great forecasting tool to have and this tutorial will walk you through the basics.

## tl;dr

1. [Replication Requirements](#replication): What you'll need to reproduce the analysis in this tutorial.
2. [Simple Exponential Smoothing](#ses): Technique for data with no trend or seasonality.
3. [Holt's Method](#holts): Technique for data with trend but no seasonality.
4. [Holt-Winters Seasonal Method](#holt-winters-seasonal-method): Technique for data with trend *and* seasonality.
5. [Model Selection and Error Calculations](#model-selection-and-error-calculations): Discussion of how to calculate errors in exponential forecasting
6. [Prediction Intervals](#prediction-intervals): Using software to simulate prediction intervals for the predicted data points


## Replication Requirements {#replication}

This tutorial uses the `forecast` and `fpp2` packages.

```{r message=FALSE}
library(forecast)
library(fpp2)          
```

Furthermore, we'll use a couple data sets to illustrate.  The `goog` data is provided by the fpp2 package and `AirPassengers` is built into base R. Let's go ahead and set up training and validation sets:

```{r}
# create training and validation of the Google stock data
goog.train <- window(goog, end = 900)
goog.test <- window(goog, start = 901)

# create training and validation of the AirPassengers data
air.train <- window(AirPassengers, end = c(1959, 12))
air.test <- window(AirPassengers, start = c(1960, 1))
```


## Simple Exponential Smoothing {#ses}

The simplest of the exponentially smoothing methods is called "simple exponential smoothing" (SES).  The key point to remember is that SES is **suitable for data with no trend or seasonal pattern**. This section will illustrate why.

For exponential smoothing, we weigh the recent observations more heavily than older observations. The weight of each observation is determined through the use of a *smoothing parameter*, which we will denote $\alpha$.  For a data set with $T$ observations, we calculate our predicted value, $\hat{y}_{T+1}$, which will be based on $y_{1}$ through $y_{T}$ as follows:

$$
\hat{y}_{T+1} = \alpha{y_T} + \alpha(1-\alpha)y_{T-1} + \dots + \alpha(1-\alpha)^{T-1}y_{1}
$$

where $0 < \alpha \leq 1$. It is also common to come to use the *component form* of this model, which uses the following set of equations.

$$
\hat{y}_{t+1} = l_{t}
$$

$$
l_{t} = \alpha{y_{t}} + (1 - \alpha)l_{t-1}
$$

In both equations we can see that the most weight is placed on the most recent observation. In practice, $\alpha$ equal to 0.1-0.2 tends to perform quite well but we'll demonstrate shortly how to tune this parameter.  When $\alpha$ is closer to 0 we consider this *slow learning* because the algorithm gives historical data more weight.  When $\alpha$ is closer to 1 we consider this *fast learning* because the algorithm gives more weight to the most recent observation; therefore, recent changes in the data will have a bigger impact on forecasted values. The following table illustrates how weighting changes based on the $\alpha$ parameter:

<div id="alpha-chart" class="section level1" style="width: 100%;">
<table style="font-size:13px;">
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
<col width="20%">
<thead>
<tr class="header">
<th align="left">Observation</th>
<th align="left">$\alpha=0.2$</th>
<th align="left">$\alpha=0.4$</th>
<th align="left">$\alpha=0.6$</th>
<th align="left">$\alpha=0.8$</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th align="left">$y_T$</th>
<th align="left">0.2</th>
<th align="left">0.4</th>
<th align="left">0.6</th>
<th align="left">0.8</th>
</tr>
<tr class="even">
<th align="left">$y_{T-1}$</th>
<th align="left">0.16</th>
<th align="left">0.24</th>
<th align="left">0.26</th>
<th align="left">0.16</th>
</tr>
<tr class="odd">
<th align="left">$y_T{T-2}$</th>
<th align="left">0.128</th>
<th align="left">0.144</th>
<th align="left">0.096</th>
<th align="left">0.032</th>
</tr>
<tr class="even">
<th align="left">$y_T{T-3}$</th>
<th align="left">0.1024</th>
<th align="left">0.0864</th>
<th align="left">0.0384</th>
<th align="left">0.0064</th>
</tr>
<tr class="odd">
<th align="left">$\vdots$</th>
<th align="left">$\vdots$</th>
<th align="left">$\vdots$</th>
<th align="left">$\vdots$</th>
<th align="left">$\vdots$</th>
</tr>
</tbody>
</table>
</div>

Let's go ahead and apply SES to the Google data using the `ses` function.  We manually set the $\alpha = .2$ for our initial model and forecast forward 100 steps with $h=100$. We see that our forecast projects a flatlined estimate into the future, which does not capture the positive trend in the data. This is why SES should not be used on data with a trend or seasonal component.

```{r, fig.align='center', fig.height=4, fig.width=8}
ses.goog <- ses(goog.train, alpha = .2, h = 100)
autoplot(ses.goog)
```

One approach to correct for this is to difference our data to remove the trend.  Now, `goog.dif` represents the change in stock price from the previous day.

```{r, fig.align='center', fig.height=4, fig.width=8}
goog.dif <- diff(goog.train)
autoplot(goog.dif)
```

Once we've differenced we've effectively removed the trend from our data and can reapply the SES model.

```{r, fig.align='center', fig.height=4, fig.width=8}
ses.goog.dif <- ses(goog.dif, alpha = .2, h = 100)
autoplot(ses.goog.dif)
```

To understand how well the model predicts we can compare our forecasts to our validation data set.  But first we need to create a differenced validation set since our training data was built on differenced data.  We see that performance measures are smaller on the test set than the training so we are not overfitting our model.

```{r}
goog.dif.test <- diff(goog.test)
accuracy(ses.goog.dif, goog.dif.test)
```

In our model we used the standard $\alpha = 0.20$; however, we can tune our alpha parameter to identify the value that reduces our forecasting error.  Here we loop through alpha values from 0.01-0.99 and identify the level that minimizes our test RMSE.  Turns out that $\alpha = 0.05$ minimizes our prediction error.

```{r, fig.align='center', fig.height=4, fig.width=6}
alpha <- seq(.01, .99, by = .01)
RMSE <- NA
for(i in seq_along(alpha)) {
  fit <- ses(goog.dif, alpha = alpha[i], h = 100)
  RMSE[i] <- accuracy(fit, goog.dif.test)[2,2]
}

alpha.fit <- data_frame(alpha, RMSE)
alpha.min <- filter(alpha.fit, RMSE == min(RMSE))
  ggplot(alpha.fit, aes(alpha, RMSE)) +
  geom_line() +
  geom_point(data = alpha.min, aes(alpha, RMSE), size = 2, color = "blue")  
```

Now we can re-fit out SES with $\alpha = 0.05$.  Our performance metrics are not significantly different from our model where $\alpha = 0.20$; however, you will notice that the predicted confidence intervals are narrower (left chart).  And when we zoom into the predicted versus actuals (right chart) you see that for most observations our predicted confidence interval did well.

```{r, fig.align='center', fig.height=4, fig.width=10}
# refit model with alpha = .05
ses.goog.opt <- ses(goog.dif, alpha = .05, h = 100)

# performance eval
accuracy(ses.goog.opt, goog.dif.test)

# plotting results
p1 <- autoplot(ses.goog.opt) +
  theme(legend.position = "bottom")
p2 <- autoplot(goog.dif.test) +
  autolayer(ses.goog.opt, alpha = .5) +
  ggtitle("Predicted vs. actuals for the test data set")

gridExtra::grid.arrange(p1, p2, nrow = 1)
```

<br>

## Holt's Method {#holts}



